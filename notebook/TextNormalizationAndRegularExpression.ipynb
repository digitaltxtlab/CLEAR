{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This note book is following the structure of the chapter 2 of the book \"*An Introduction to Natural Language Processing,\n",
    "Computational Linguistics, and Speech Recognition*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practical Info: The hashtag symbol \"#\" in the codefields means that the text directly after does not affect the code in any way. It is used to comment on the code. If there is a \"#\" in front of a line of code, then the code is disabled.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Techniques for Preprocessing （text normalization)\n",
    "\n",
    "This notebook introduces the basic techniques to do preprocessing or **text normalization**. In general, text normalization is a set of procedures to convert text to a more convenient, standard form. This process includes **tokenization**,**lemmatization** and **stemming**. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regular Expression：**\n",
    "\n",
    "This is a fundamental tool for language processing. In this notebook we will show you how to use it to search your text for specific expression, whether it's words, numbers or any combination of letters, special characters and numbers.\n",
    "\n",
    "**Tokenization:** \n",
    "\n",
    "refers to the task of separating the text word by word. Most of the latin languages can be separated by \"white space\", but sometimes it is necessary to treat words differently, for example, we often treat \"New York\" as a single word.\n",
    "\n",
    "**Lemmatization** and **stemming** are closely related\n",
    "\n",
    "**Lemmatization:** will map all the different occurrences of a word to its root, for example, sang, sung, and sing will all be mapped to the verb sing. \n",
    "\n",
    "**Stemming:** is a simpler version of lemmatization, it only strips the suffix from the end of the words.\n",
    "\n",
    "\n",
    "Each topic is divided into several sub-sections, and each section has an example after the definition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Content\n",
    "\n",
    "### Regular Expression\n",
    "1. Basic Regular: Expression Patterns\n",
    "    - 1.1 Basic Regular: **[ ]**，**^**， and **-** \n",
    "    - 1.2 Basic Regular: ? * .\n",
    "    - 1.3 Basic Regular: Anchors\n",
    "    - 1.4 Practice\n",
    "2. Disjunction, Grouping and Precedence\n",
    "    - 2.1 Disjunction\n",
    "    - 2.2 Grouping and Precedence\n",
    "3. An Example of Regular Expression in Use\n",
    "4. Summary of Regular Expression\n",
    "\n",
    "### Tokenization and Normalization\n",
    "1. Tokenization\n",
    "2. Collapsing Words: LEmmatization and Stemming\n",
    "3. Sentence Segmentation and Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expression is a useful tool when doing text normalization， it is a language for specifying the strings to be searched. Many string processing functions in python support the use of regular expression, here we use **re.findall** as an example to show how the regular expression works, in the end of this section, we will introduce more functions which could use regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this the library for using rugular expression in python\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1: Basic Regular Expression Patterns\n",
    "The simplest regular expression is to match a sequence of simple characters. For example, suppose we have the following text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"Text\" will be used in the regular expressions, to tell the notebook which text to search through\n",
    "Text = \"Though hundreds of thousands and Thousands had done their very best to disfigure the small piece of land on which they were crowded together\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we want to match the words \"thousands\". Then we will simply use /thousands/ to match the words. The **findall** function will check for a match anywhere in the text, then return all the matched strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note on the function:**\n",
    "The “r” at the start of the pattern string (in the brackets) designates a python raw string. Therefore the word you want to match, needs to be specified as follows: **(r'word'**,Text**)**. And (r'word'**,Text**) tells the notebook which text to search (as we defined above).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels \"matchObj\" as containing the results of the function\n",
    "matchObj = re.findall(r'thousands',Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thousands']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prints the results of the function\n",
    "matchObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Regular 1.1**： **[ ]**，**^**， and **-** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So far the regular expression only matches 'thousands' exactly. That is, every occurrence of 'thousands' written with a lowercase 't' and plural. In order to include other occurrences of 'thousands', the regular expression needs to be expanded:\n",
    "\n",
    "- **[ ]** = Match one of the characters in the brackets\n",
    "\n",
    "Suppose now we want to match both **'thousands'** and **'Thousands'**, this is where **\"[ ]\"** comes to play a role (- the regular expression with square brackets will match both strings of characters inside the brackets). The new regular expression needs to look as follows: **(r'[Tt]housands)** \n",
    "\n",
    "**Example: Find \"thousands\" in lower and upper case**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels \"matchObj\" as containing the results of the function\n",
    "matchObj = re.findall(r'[Tt]housands',Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thousands', 'Thousands']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prints the results of the function\n",
    "matchObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the square brackets, we can match all the single digits in a text: **(r'[1234567890]')** \n",
    "\n",
    "or match any capital letter in a text: **(r'[ABCDEFGHIJKLMNOPQRSTUVWXYZ]')**\n",
    "\n",
    "Let's look at an example of each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"Text\" will be used in the regular expressions, to tell the notebook which text to search through\n",
    "Text = \"An apple falls from the tree, there are 2 Birds and 3 Monkeys on the tree\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Find all the numbers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels \"matchObj\" as containing the results of the function\n",
    "matchObj = re.findall(r'[1234567890]',Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '3']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prints the results of the function\n",
    "matchObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Find all the capital letters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels \"matchObj\" as containing the results of the function\n",
    "matchObj = re.findall(r'[ABCDEFGHIJKLMNOPQRSTUVWXYZ]',Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'M']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prints the results of the function\n",
    "matchObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue to explore some other tools which you can use with **[ ]**. Using these tools will give you more specific results:\n",
    "\n",
    "- **-** = Range indicator\n",
    "\n",
    "The brackets can be used with the dash **-** to specify any one character in a range. For example: the pattern **[1-9]** specifies any one of the characters from 1 to 9 (like you saw above: (r'[123456789]'). And the pattern **[A-Z]** is also equivalent to the expression we used above: *[ABCDEFGHIJKLMNOPQRSTUVWXYZ]*.\n",
    "\n",
    "- **^** = When [^inside brackets], it means \"not\"\n",
    "\n",
    "The caret tool **^** \"not\" when it is put in front of the first symbol after the open square bracket. For example, **[^a-z]** means to match any single character except the lowercase alphabet. That means it will still match digits and capital letters.\n",
    "\n",
    "Let's see two examples: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text = \"An apple falls from the tree, there are 2 Birds and 3 Monkeys on the tree\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Find all numbers in \"a range from 1 to 9\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchObj = re.findall(r'[1-9]',Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '3']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Find all \"characters and numbers\", except \"lower case alphabet\"**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchObj = re.findall(r'[^a-z]',Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ',',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '2',\n",
       " ' ',\n",
       " 'B',\n",
       " ' ',\n",
       " ' ',\n",
       " '3',\n",
       " ' ',\n",
       " 'M',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Regular 1.2**: **?**, *****, **+**,and **.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add another tool:\n",
    "\n",
    "- *?* = Once or none\n",
    "\n",
    "The question mark means \"the preceding character or nothing\". For example, **(r'falls?)** will match both \"fall\" and \"falls\". \n",
    "\n",
    "See the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text = \"An apple falls from the tree while children fall from another tree. One apple is falling. Is it false?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Find all instances of words starting with \"fall\" and \"falls\", output only \"fall\" and \"falls\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchObj = re.findall(r'falls?',Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['falls', 'fall', 'fall']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- ***** = Zero or more times\n",
    "\n",
    "The asterisk ***** matches \"zero or more occurrences of the immediately previous character\". For example, **(r'ab*')** will match all the following text: \"ab\", \"abb\", \"abbbb\". \n",
    "\n",
    "Interestingly, we can use **(r'[0-9][0-9]*')** to match any integer. \n",
    "\n",
    "*Side note: An integer (from the Latin integer meaning \"whole\") is a number that can be written without a fractional component. For example, 21, 4, 0, and −2048 are integers, while 9.75, 5 1/2, and √2 are not. [Source](https://en.wikipedia.org/wiki/Integer)*\n",
    "\n",
    "**Example: Find all instances of \"any number\", ouput the exact number**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['57', '2', '300', '1234']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text = \"There are 57 apples and 2 birds on the tree 300, 1234\"\n",
    "matchObj = re.findall(r'[0-9][0-9]*',Text)\n",
    "matchObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Find all instances of \"a\" and \"a followed by any other character\", output only \"a\" and \"a\" followed by b**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ab', 'abb', 'abbbb', 'abbbb', 'a', 'a', 'ab']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text = \"Some dummy words； ab, abb, abbbb, abbbb, a, afg, abcde\"\n",
    "matchObj = re.findall(r'ab*',Text)\n",
    "matchObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *+* = One or more\n",
    "\n",
    "The **+** tool has almost the same function as *****. The difference is: it matches \"**one** or more occurrences of the immediately previous character\" (as opposed to \"**zero** or more...\")\n",
    "\n",
    "If we use \"ab+\" instead of \"ab*\", it will only match the \"ab\", \"abb\", \"abbb...\", but not \"a\".\n",
    "\n",
    "See in the example:\n",
    "\n",
    "**Example: Find all instances of \"a\" immediately followed by \"b\", output only \"ab\" followed by b**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ab', 'abb', 'abbbb', 'abbbb', 'ab']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchObj = re.findall(r'ab+',Text)\n",
    "matchObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **.** = Any character except line break\n",
    "\n",
    "The period **.** is a very important expression. It is used to match any single character, also within a word. For example, if you want to match any occurrence of the words \"sing, sang, sung and song\", use: **(r's.ng')**\n",
    "\n",
    "Take a look at the example below:\n",
    "\n",
    "**Example: Find all instances of \"beg_n\"**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['began', 'begin']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text = \"began is the past tense of begin not begging\"\n",
    "matchObj = re.findall(r'beg.n',Text)\n",
    "matchObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Regular 1.3:** Anchors\n",
    "\n",
    "Anchors are special characters that anchor regular expressions to particular places in a string. \n",
    "\n",
    "- **^** = Start of string or start of line depending on multiline mode. (But when [^inside brackets], it means \"not\")\n",
    "\n",
    "Caret **^** is used to match the start of a line, so **(r'^began')** will only match the word \"began\" at the start of a line.\n",
    "\n",
    "- **$** = \tEnd of string or end of line depending on multiline mode.\n",
    "\n",
    "The dollar sign **$** is used to match the characters or digits at the end of a line. So **(r'began§')** will only match \"began\" if it appears at the end of a line.\n",
    "\n",
    "See the three examples below. *(Note the period at the end of \"end\" is to include all instances of words that contain end immediately followed by more characters or digits.)*\n",
    "\n",
    "**Example: Find all instances of \"end\" at the beginning of a line**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['end1']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text = \"end1 of the a period of life often indicates the beginning of another journey,so end2ing is not always the end3\"\n",
    "matchObj = re.findall(r'^end.',Text)\n",
    "matchObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Example: Find all instances of \"end\" followed by \"any character or number\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['end1', 'end2', 'end3']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchObj = re.findall(r'end.',Text)\n",
    "matchObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Find all instances of \"end\" at the end of a line**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['end3']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchObj = re.findall(r'end.$',Text)\n",
    "matchObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.4 Practice\n",
    "\n",
    "You're welcome to use the code field below to practice the regular expressions you've learned above. We provided a text you can practice on, but you can also replace it with your own text if you want to (just copy and paste it inside of the quotation marks).\n",
    "\n",
    "A little recap, these are the regular expression tools you've learned so far:\n",
    "\n",
    "**(r'xxx',Text)**\n",
    "\n",
    "**Tools**\n",
    "- **[ ]** = Match one of the characters in the brackets\n",
    "- **-** = Range indicator\n",
    "- **^** = When [^inside brackets], it means \"not\" (also means: start of string or start of line depending on multiline mode. )\n",
    "- *?* = Once or none\n",
    "- ***** = Zero or more times\n",
    "- *+* = One or more\n",
    "- **.** = Any character except line break\n",
    "\n",
    "**Anchors**\n",
    "\n",
    "- **^** = Start of string or start of line depending on multiline mode. (But when [^inside brackets], it means \"not\")\n",
    "- **$** = \tEnd of string or end of line depending on multiline mode.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\"Text\" will be used in the regular expressions, to tell the notebook which text to search through\n",
    "Text = \"Top Three Reasons Why TV Remote Controls Are Frustrating to Use. The average U.S. household has five remote controls. In fact, many households have 10 or more. But despite being introduced over 50 years ago, TV remote controls still maintain a basic design that can be frustrating to use. Below are the top three reasons why TV remote controls are frustrating to use: #3 – Commonly used buttons are too small, making their use awkward. The most commonly used buttons are frequently the smallest buttons. They also are usually surrounded by lots of other small buttons. This is especially problematic in low light. #2 – Too many rarely used buttons getting in the way. Most remotes have from 40 to 60 buttons, yet only about 10 of them are commonly used. All of these extra buttons make it difficult to find the buttons that are actually used most often. This, too, is especially problematic in low light. #1 – Difficult to use in low light, impossible to use in the dark. Nearly 90 percent of remote controls do not have backlighting. Considering the popularity of watching television with the lights off, along with the fact that 75 percent of Americans have vision problems, it is surprising so few are backlit. Backlighting is not a perfect solution, though, because it only illuminates the buttons but not the text next to the buttons.\"\n",
    "#labels \"matchObj\" as containing the results of the regular expression\n",
    "matchObj = re.findall(r'ENTER REGULAR EXPRESSION HERE',Text)\n",
    "#prints the results of the regular expression\n",
    "matchObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Disjunction, Grouping and Precedence\n",
    "\n",
    "### 2.1 Disjunction\n",
    "\n",
    "- **|** = Alternation / OR operand\n",
    "\n",
    "Disjunction operator **|** (also called the pipe symbol), is similar to \"or\" in our natural language. Suppose we want to search for \"bird or monkey\" in the sentence, how can we do this? You may think about using **[ ]** to do this, but the problem is that we can only apply the bracket to single characters.\n",
    "\n",
    "This is how you search for x or y: **(r'x|y')**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bird', 'monkeys', 'bird', 'bird']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text = \"Here is a bird and some monkeys on the tree. There is one more monkey and some birds in the air. Look abird.\"\n",
    "matchObj = re.findall(r'bird|monkeys',Text)\n",
    "matchObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: There are three results for \"bird\" because it includes bird as part of any word including \"birds\" (plural) and \"abird\" (typo). It does not include \"monkey\" because it only matches \"monkey**s**\" exactly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Grouping and Precedence\n",
    "\n",
    "- **()** = Capturing group\n",
    "\n",
    "The parenthesis symbol **()** is used for both Grouping and Precedence. \n",
    "\n",
    "Suppose you want to match both \"study\" and \"studies\", in this case, we may want to use the disjunction operator, but \"study|ies\" will not match study and studies at the same time, instead, it will match \"study\" and \"ies\". This is because by default, the sequence like \"study\" and \"ies\" take precedence over the disjunction operator **|**. To solve this problem, we can use **()** to specify the precedence as we want. So **(r'stud(y)|(ies)')** will do what we want.\n",
    "\n",
    "In general, adding the parenthesis around the text is helping us to group things, but remember, the grouping is realized by changing the precedence.\n",
    "\n",
    "**Example: Find all instances of \"study\" and \"ies\" using |, output \"study\" and \"ies\"**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['study', 'ies', 'ies']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text = \"Tom likes to study history, while his brother studies maths in the college. It's not lies.\"\n",
    "matchObj = re.findall(r'study|ies',Text)\n",
    "matchObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Find all instances of \"study\" and \"ies\", output \"y\" and \"ies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('y', ''), ('', 'ies'), ('', 'ies')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text = \"Tom likes to study history, while his brother studies maths in the college. It's not lies. There is a stud y.\"\n",
    "matchObj = re.findall(r'stud(y)|(ies)',Text)\n",
    "matchObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "As you can see in the second example above, the output is not \"study and studies\", it's \"y and ies\". If we want the output to be \"study and studies\" we need to add another tool:\n",
    "\n",
    "- **?:** = Non-capturing group\n",
    "\n",
    "**What is the problem?**\n",
    "\n",
    "**()** has two meanings: \n",
    "- one is specify the precedence \n",
    "- the other is to actually store the things in the bracket in the computer and output it when necessary.\n",
    "\n",
    "Basically, if we merely put **()** here, the findall fucntion will only return the content in the bracket. In this case, only return **\"y,ies\"**. Sometimes we may need to use **()** because we want to match some pattern but only return part of words within this pattern.\n",
    "\n",
    "**Solution:**\n",
    "Using **(?:)** will specify the preference and not only output the content of the brackets, but all connected characters and digits.\n",
    "\n",
    "Take a look at the examples. \n",
    "\n",
    "1. Uses only brackets\n",
    "2. Uses the **?:** tool\n",
    "\n",
    "**Example: Find all instances of \"study\" and \"studies\", output \"y\" and \"ies\"**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y', 'ies']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchObj = re.findall(r'stud(y|ies)',Text)\n",
    "matchObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Example: Find all instances of \"study\" and \"studies\", output \"study\" and \"studies\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['study', 'studies']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchObj = re.findall(r'stud(?:y|ies)',Text)\n",
    "matchObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. An example of Regular Expression in Use\n",
    "\n",
    "Here is an example showing how we can construct a regular expression step by step. For this example we will use an article about the history of England. \n",
    "\n",
    "Suppose now we want to have a list of all references to time as digits (= years) that occur in the article, and we need to write the regular expression to help us find them. Here is how this passage could look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This loads an external text file and labels the file as \"data\"\n",
    "with open('History of England(used for regex tutorial).txt', 'rb') as myfile:\n",
    "    data=myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'History of England\\r\\nFrom Wikipedia, the free encyclopedia\\r\\n\\r\\nEngland became inhabited more than 800,000 years ago, as the discovery of stone tools and footprints at Happisburgh in Norfolk has revealed.[1] The earliest evidence for early modern humans in North West Europe, a jawbone discovered in Devon at Kents Cavern in 1927, was re-dated in 2011 to between 41,000 and 44,000 years old.[2] Continuous human habitation in England dates to around 13,000 years ago (see Creswellian), at the end of the'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.decode(\"utf-8\")\n",
    "data[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "By looking at the text, we can see that there are three \"types\" of ways to mention years: \n",
    "\n",
    "1. **In 2011** where \"2011\" can be replaced by any number \n",
    "2. **4000 BC/AD** where \"4000\" can be replaced by any number \n",
    "3. **1495–1497** where \"1495\" and \"1497\" can be replaced by any number \n",
    "\n",
    "We will write the regular expression to capture these three formats in the following:\n",
    "**(r'[Ii]n [0-9]+',data)**\n",
    "\n",
    "- \"[Ii]n\" = matches any occurence of \"In and in\"\n",
    "- \"[0-9]\" = matches any digit between \"0 and 9\"\n",
    "- \"+\" = matches more than one digit at a time\n",
    "- \",data\" = the label we gave the text \n",
    "\n",
    "**Example: Find all instances of \"in\" followed by \"numbers\"**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in 1927',\n",
       " 'in 2011',\n",
       " 'In 1066',\n",
       " 'in 1485',\n",
       " 'in 1660',\n",
       " 'in 1707',\n",
       " 'In 55',\n",
       " 'In 2003',\n",
       " 'in 43',\n",
       " 'in 60']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchObj = re.findall(r'[Ii]n [0-9]+',data)\n",
    "#The [:10] means is will show only the first 10 results.\n",
    "matchObj[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In the previous example we got all instances of numbers appearing with \"I/in\" in front of it, but as mentioned before, we also have numbers like **\"4000 BC or AD\"**\n",
    "\n",
    "Let's find those next with:\n",
    "**(r'[0-9]+ (?:BC|AD)',data)**\n",
    "\n",
    "- \"[0-9]\" = matches any digit between \"0 and 9\"\n",
    "- \"+\" = matches more than one digit at a time\n",
    "- \"(?:BC|AD)\" = matches any occurrence of \"BC or AD\"\n",
    "\n",
    "\n",
    "**Example: Find all instances of \"numbers\" followed by \"BC\" or \"AD\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000 BC',\n",
       " '6500 BC',\n",
       " '9000 BC',\n",
       " '4000 BC',\n",
       " '3806 BC',\n",
       " '2500 BC',\n",
       " '800 BC',\n",
       " '400 BC',\n",
       " '400 BC',\n",
       " '325 BC',\n",
       " '150 BC',\n",
       " '300 BC',\n",
       " '100 BC',\n",
       " '54 BC',\n",
       " '43 AD',\n",
       " '54 AD',\n",
       " '60 AD',\n",
       " '138 AD',\n",
       " '700 AD']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchObj = re.findall(r'[0-9]+ (?:BC|AD)',data)\n",
    "matchObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But wait a minute! \n",
    "\n",
    "If you look at the results carefully, you can see something weird. What does **\"000 BC\"** mean? \n",
    "\n",
    "It turns out, some of the years are expressed using in this format: **\"9,000 BC\"**, so there is a comma inserted in the numbers somewhere. \n",
    "\n",
    "**Solution:**\n",
    "\n",
    "Instead of using \"[0-9]+\", which matches the normal integer, we need to add **\"(,[0-9]{3})\\*\"** to match the integers containing the comma.\n",
    "\n",
    "The new regular expression now looks like this: **(r'[0-9]+(?:,[0-9]{3})* (?:BC|AD)',data)**\n",
    "\n",
    "- \"[0-9]+\" = matches any digit between \"0 and 9\", and more than one at a time\n",
    "- \"(?:,[0-9]{3})\\*\" = matches digits with commas inside\n",
    "    - \"?:,\" = includes the comma among numbers in the result\n",
    "    - \"[0-9]\" = specifies that the comma needs to be followed by numbers\n",
    "    - \"{3}\" = (def: Exactly three times), specifies that comma is followed by 3 numbers\n",
    "    - \"\\*\" = matches zero or more instances of the defined character, in this case any instance of \"a comma followed by maximum 3 numbers\"\n",
    "- \"(?:BC|AD)\" = matches any occurrence of \"BC or AD\"\n",
    "- \",data\" = the label we gave the text\n",
    "\n",
    "**Example: Find all instances of \"numbers\" and \"numbers containing a comma\" followed by \"BC\" or \"AD\"**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9,000 BC',\n",
       " '6500 BC',\n",
       " '9000 BC',\n",
       " '4000 BC',\n",
       " '3806 BC',\n",
       " '2500 BC',\n",
       " '800 BC',\n",
       " '400 BC',\n",
       " '400 BC',\n",
       " '325 BC',\n",
       " '150 BC',\n",
       " '300 BC',\n",
       " '100 BC',\n",
       " '54 BC',\n",
       " '43 AD',\n",
       " '54 AD',\n",
       " '60 AD',\n",
       " '138 AD',\n",
       " '700 AD']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchObj = re.findall(r'[0-9]+(?:,[0-9]{3})* (?:BC|AD)',data)\n",
    "matchObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now we matched all occurrences of years followed by BC or AD, but what about occurrences of time periods?\n",
    "\n",
    "Let's take a look:\n",
    "\n",
    "**(r'\\w+–\\w+',data)**\n",
    "\n",
    "- **\\w** = matches unicode letters, ideograms, digits, or underscores\n",
    "- **+** = matches more than one at a time\n",
    "- **–** = matches characters connected by a dash\n",
    "\n",
    "This regular expression searches for occurrences of a word or digits, followed by a dash, followed by a word or digits.\n",
    "\n",
    "Here is the example:\n",
    "\n",
    "**Example: Find all instances of \"letters or digits\" followed by \"-\" followed by \"letters or digits\" (without spaces)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1135–1154',\n",
       " '1337–1453',\n",
       " '1649–1653',\n",
       " '1653–1659',\n",
       " '18th–19th',\n",
       " '3807–3806',\n",
       " '600–400',\n",
       " '150–100',\n",
       " '1139–1153',\n",
       " '1216–1272',\n",
       " '1272–1307',\n",
       " '1315–1317',\n",
       " '1327–1377',\n",
       " '1455–1485',\n",
       " '1470–1471',\n",
       " '1495–1497',\n",
       " '1516–1558',\n",
       " '1527–1598',\n",
       " '1558–1603',\n",
       " '1585–1604',\n",
       " '1585–1603',\n",
       " '1630–1660',\n",
       " '1642–1645',\n",
       " '18th–19th',\n",
       " '1832–1974',\n",
       " '1945–present',\n",
       " '1945–present',\n",
       " '1985–86']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchObj = re.findall(r'\\w+–\\w+',data)\n",
    "matchObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 4. Summary of Regular Expression\n",
    "\n",
    "Regular expressions are an extremly powerful tool, because they are fast to execute and can be used to match almost any pattern. \n",
    "\n",
    "One thing you need to remember is, that regular expressions only match exaclty what you tell it to match. It is always important to check the results to see if the regular expression matched what you wanted it to or if it included/excluded something.\n",
    "\n",
    "Here we only have a very brief introduction to regular expressions, and a lot of things haven't been mentioned. Fortunately, there are many websites with cheatsheets that can give you a quick overview of the tools. Alternatively you can also google for regular expressions examples to see what other people did and be inspired to construct your own.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Tokenization and Normalizaiton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Tokenization\n",
    "\n",
    "Tokenization is used to segment the running text into words, but just like other preprocessing tasks, word tokenization is highly dependent on the task we want to perform. \n",
    "\n",
    "For example, in some tasks, we want to keep the punctuation in our sentence and use it as a seperate token, but most of the time, if we only care about the *semantic level* of the text (the meaning of the the text)，we can ignore the the punctuation and other non-alphanumeric characters in the text. \n",
    "\n",
    "**Note:** Non-alphanumeric characters means all characters that are not aphabetical (abc...) and not numeric (123...), like: **!\"#€%&/()=?**\n",
    "\n",
    "Here we provide two functions: \n",
    "1. remove the non-alphanumeric characters\n",
    "2. tokenize the text into words.\n",
    "\n",
    "But first we need to add text:\n",
    "\n",
    "**Add text** \n",
    "\n",
    "This is an example text with randomly added non-alphanumerical characters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"data\" will be used in the functions, to tell the notebook which text to search through\n",
    "data = \"emmm... There is arc**haeological evidence of hu$man occupation of the Rome area from approximately 14,000 years ago, but the dense layer of much younger debris obscures Palaeolithic and Neolithic sites.[6] Evidence of stone tools, pottery, and stone weapons attest to about 10,000 years of human presence. Several excavations support the view that Rome grew from pastoral settlements on the Palatine Hill built above the area of the future Roman Forum. Between the end of the bronze age and the beginning of the Iron age, each hill between the sea and the Capitol was topped by a village (on the Capitol Hill, a village is attested since the end of the 14th century BC).[22]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Remove non-alphanumeric characters**\n",
    "\n",
    "Below we import the regular expressions library called \"re\". Then we write the code to remove the non-alphanumeric characters.\n",
    "\n",
    "This function is actually using a very simple regular expression to match all the alphanumerical characters (represented by \\w) and space (represented by \\s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports regular expressions library\n",
    "import re\n",
    "#removes the non-alphanumeric characters based on \"re\"\n",
    "def re_nalpha(str):\n",
    "    pattern = re.compile(r'[^\\w\\s]', re.U)\n",
    "    return re.sub(r'\\n','',re.sub(r'_', '', re.sub(pattern, '', str)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1 Output - Remove non-alphanumeric characters**\n",
    "\n",
    "We defined *re_nalpha* above to remove all the non-alphanumeric characters and we tell it in the brackets to remove the characters from the text we labelled \"data\" (see the \"add text\" field, where it says **data = \"...\"**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'emmm There is archaeological evidence of human occupation of the Rome area from approximately 14000 years ago but the dense layer of much younger debris obscures Palaeolithic and Neolithic sites6 Evidence of stone tools pottery and stone weapons attest to about 10000 years of human presence Several excavations support the view that Rome grew from pastoral settlements on the Palatine Hill built above the area of the future Roman Forum Between the end of the bronze age and the beginning of the Iron age each hill between the sea and the Capitol was topped by a village on the Capitol Hill a village is attested since the end of the 14th century BC22'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labels \"alpha\" as containing the text without non-alphanumeric characters\n",
    "alpha = re_nalpha(data)\n",
    "#prints the text without non-alphanumeric characters\n",
    "alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*Note: Removing non-alphanumeric characters might lead to some unexpected results like this:*\n",
    "- Original: **sites.[6]**\n",
    "- After removing alphanumeric characters: **sites6**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Tokenize the text into words**\n",
    "\n",
    "We already imported the regular expressions library above, so we don't need to do it again here. We only need to write the code to tokenize the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizes the text into words\n",
    "def word_tokenize(text): return re.findall(r'\\w+', text.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Output - Tokenize text into words**\n",
    "\n",
    "Above we defined \"word_tokenize\" to tokenize the words and under \"1.1 Output\" we labelled the cleaned text \"alpha\".\n",
    "\n",
    "We could also tokenize the original text by replacing \"alpha\" with \"data\" in the brackets, but then the tokenized words would still contain the non-alphanumeric characters - and that's not what we want.\n",
    "\n",
    "- **[:10]** = show only the first 10 results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emmm',\n",
       " 'there',\n",
       " 'is',\n",
       " 'archaeological',\n",
       " 'evidence',\n",
       " 'of',\n",
       " 'human',\n",
       " 'occupation',\n",
       " 'of',\n",
       " 'the']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(alpha)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sidenote on Languages**\n",
    "\n",
    "Tokenization in English and other latin-origin languages is relatively easy, but when it comes to other languages like Chinese, tokenizaion is actually a challenging task. \n",
    "\n",
    "**Sidenote on Special Cases**\n",
    "\n",
    "- Also, there are some \"special cases\" we haven't talk about. For example, how do we deal with **\"you're\"** case? Should we seperate it into **\"you are\"** or just a single string **\"you're\"**?  \n",
    "- And should we regard \"New York\" as a single string or two words? \n",
    "\n",
    "In these cases, we cannot merely rely on the space between the words to do tokenization. More advanced algorithm will be needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Collapsing Words: Lemmatization and Stemming\n",
    "\n",
    "**Lemmatization** is the task of determining if two words have the same root. When we perform the lemmatization operation to text, all the words that have the same root/origin will be mapped to the origin. \n",
    "\n",
    "For example, these three words **\"am\"**,**\"is\"**,**\"are\"** will be mapped to **\"be\"**.\n",
    "\n",
    "Lemmatization requires a very complex algorithm, so in many cases, we will do a simpler version of lemmatization: \n",
    "\n",
    "**Stemming** - just removes the suffix of the words. In this case, **\"cats\"** will become **\"cat\"**, **\"heights\"** will become **\"height\"**. \n",
    "\n",
    "Of course, not all the stemming is just removing the \"s\" character at the end of the word, depending on the algorithm we use, it will have different stemming methods. The most widely used algorithm is proposed by Porter(1980). It will, for example, map **\"accurate\"** to **\"accur\"**. \n",
    "\n",
    "Let's look at an example of stemming using the nltk library:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports the Porter Stemmer from the nltk stemming library\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shortens PorterStemmer to ps, so we don't have to write the whole expression every time\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rome',\n",
       " 'area',\n",
       " 'from',\n",
       " 'approximately',\n",
       " '14000',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'but',\n",
       " 'the',\n",
       " 'dense',\n",
       " 'layer',\n",
       " 'of',\n",
       " 'much',\n",
       " 'younger',\n",
       " 'debris',\n",
       " 'obscures',\n",
       " 'palaeolithic',\n",
       " 'and',\n",
       " 'neolithic',\n",
       " 'sites6']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labels wordList to contain the tokenized words from the \"alpha\" text (the one we tokenized above)\n",
    "wordList = word_tokenize(alpha)[10:30]\n",
    "#prints the list of tokenized words\n",
    "wordList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rome\n",
      "area\n",
      "from\n",
      "approxim\n",
      "14000\n",
      "year\n",
      "ago\n",
      "but\n",
      "the\n",
      "dens\n",
      "layer\n",
      "of\n",
      "much\n",
      "younger\n",
      "debri\n",
      "obscur\n",
      "palaeolith\n",
      "and\n",
      "neolith\n",
      "sites6\n"
     ]
    }
   ],
   "source": [
    "#prints the list of stemmed words\n",
    "for w in wordList:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More info about Porter Stemmer**\n",
    "\n",
    "The PorterStemmer is based on a set of rules, for example, one of the rules is to convert all the \"SSES\" to \"SS\", following this rule, \"grasses\" will be converted to \"grass\". The list of rules and the code for implementing the algorithm can be found on [this website](https://tartarus.org/martin/PorterStemmer/index.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sentence Segmentation and Summary\n",
    "\n",
    "Sentence segmentation is another important step in text processing, similar to *word tokenization*, but this task is to split the text at the sentence level. \n",
    "\n",
    "While sentence segmentation seems easy to do, the state-of-the-art algorithm is to rely on machine learning. Some people may argue we can simply use the punctuation as the boundary of sentence, but punctuation is often ambiguous. For example, the period character **\".\"** can either be a sentence boundary marker or a marker of abbrevations like **\"Mr.\"** or **\"etc.\"**.\n",
    "\n",
    "In this repository, we have some preprocessing tools built by ourselves. You can find the scripts for tokenization under *CLEAR/tools/scripts_py/preprocessing.py* , but for the stemming part, we rely on the **nltk** library, which provides many useful functions for preprocessing.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
